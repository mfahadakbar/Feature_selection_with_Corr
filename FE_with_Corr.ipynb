{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FE_with_Corr.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mfahadakbar/Feature_selection_with_Corr/blob/master/FE_with_Corr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTDUw4FlaM-C",
        "colab_type": "code",
        "outputId": "51a00274-f95d-4430-c155-56da365013a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NUhKfWrW48F",
        "colab_type": "code",
        "outputId": "926c7981-dc46-41b5-dfb5-b31594feaf7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "#keeping in view corelation with the taget variable . We will call this fuunction whenever we need to reduce our dimentions\n",
        "  def c_f(input_data,threshold=Corr_TH,tar=target):\n",
        "\n",
        "    global data1\n",
        "    # make an corelation db with abs corelation db\n",
        "    corr_matrix = abs(data1.corr())\n",
        "\n",
        "    # for every diagonal value, make it Nan\n",
        "    corr_matrix.values[tuple([np.arange(corr_matrix.shape[0])]*2)] = np.NaN\n",
        "\n",
        "    # Now Calculate the average correlation of every feature with other, and get a pandas data frame\n",
        "    avg_cor = pd.DataFrame(corr_matrix.mean())\n",
        "    avg_cor['feature']= avg_cor.index\n",
        "    avg_cor.reset_index(drop=True, inplace=True)\n",
        "    avg_cor.columns =  ['avg_cor','features']\n",
        "    \n",
        "    # Calculate the corelation with the target\n",
        "    targ_cor = pd.DataFrame(corr_matrix[tar].dropna())\n",
        "    targ_cor['feature']= targ_cor.index\n",
        "    targ_cor.reset_index(drop=True, inplace=True)\n",
        "    targ_cor.columns =  ['target_cor','features']\n",
        "\n",
        "    # Now, add a column for variable name and drop index\n",
        "    corr_matrix['column'] = corr_matrix.index\n",
        "    corr_matrix.reset_index(drop=True,inplace=True)\n",
        "\n",
        "    # now we need to melt it , so that we can corelation pair wise , with two columns \n",
        "    cols =corr_matrix.column\n",
        "    melt = corr_matrix.melt(id_vars= ['column'],value_vars=cols).sort_values(by='value',ascending=False).dropna()\n",
        "\n",
        "    # now bring in the avg corelation for first of the pair\n",
        "    merge = pd.merge(melt,avg_cor,left_on='column',right_on='features').drop('features',axis=1)\n",
        "\n",
        "    # now bring in the avg corelation for second of the pair\n",
        "    merge = pd.merge(merge,avg_cor,left_on='variable',right_on='features').drop('features',axis=1)\n",
        "    \n",
        "    # now bring in the target corelation for first of the pair\n",
        "    merge = pd.merge(merge,targ_cor,left_on='column',right_on='features').drop('features',axis=1)\n",
        "\n",
        "    # now bring in the avg corelation for second of the pair\n",
        "    merge = pd.merge(merge,targ_cor,left_on='variable',right_on='features').drop('features',axis=1)\n",
        "\n",
        "    # sort and save\n",
        "    merge = merge.sort_values(by='value',ascending=False)\n",
        "\n",
        "    # we need to now eleminate all the pairs that are actually duplicate e.g cor(x,y) = cor(y,x) , they are the same , we need to find these and drop them\n",
        "    merge['all_columns'] = merge['column'] + merge['variable']\n",
        "\n",
        "    # this puts all the coresponding pairs of features togather , so that we can only take one, since they are just the duplicates\n",
        "    merge['all_columns'] = [sorted(i) for i in merge['all_columns'] ]\n",
        "\n",
        "    # now sort by new column\n",
        "    merge = merge.sort_values(by='all_columns')\n",
        "\n",
        "    # take every second colums\n",
        "    merge = merge.iloc[::2, :]\n",
        "\n",
        "    # make a rinking column to eliminate features\n",
        "    merge['rank_x'] = round((merge['avg_cor_y']- merge['avg_cor_x']) + (merge['target_cor_x'] - merge['target_cor_y']),6) # round it to 6 digits\n",
        "\n",
        "    ## Now there will be rows where the rank will be exactly zero, these is where the value (corelartion between features) is exactly one ( like price and price^2)\n",
        "    ## so in that case , we can simply pick one of the variable\n",
        "    # but since , features can be in either column, we will drop one column (say 'column') , only if the feature is not in the second column (in variable column)\n",
        "    # both equations below will return the list of columns to drop from here \n",
        "    # this is how it goes\n",
        "\n",
        "    ## For the portion where corelation is exactly one !\n",
        "    one = merge[merge['rank_x']==0]\n",
        "\n",
        "    #[i for i in pd.unique(small['column']) if i not in pd.unique(small['variable'])]\n",
        "    to_drop =(list(set(one['column'])-set(one['variable'])))\n",
        "\n",
        "    ## now we are to treat where rank is not Zero and Value (corelation) is greater than a specific threshold\n",
        "    non_zero = merge[(merge['rank_x']!= 0.0) & (merge['value'] >= Corr_TH)]\n",
        "\n",
        "    # pick the column to delete\n",
        "    non_zero_list = list(np.where(non_zero['rank_x'] < 0 , non_zero['column'], non_zero['variable']))\n",
        "\n",
        "    # add two list\n",
        "    to_drop = to_drop + non_zero_list\n",
        "\n",
        "    #make sure that target column is not a part of the list\n",
        "    try:\n",
        "      to_drop.remove(tar)\n",
        "    except:\n",
        "      to_drop\n",
        "\n",
        "    #Final Step, drop the columns from data\n",
        "    data1.drop(to_drop,axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-a3b11b31135c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mc_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCorr_TH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;31m# make an corelation db with abs corelation db\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mcorr_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Corr_TH' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGYneAEJXluZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "data1 = pd.read_csv('/content/drive/My Drive/Steve_Assignments/OJ_copy_transformed.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFSKl_98aCws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Corr_TH = 0.45\n",
        "target = 'Purchase'\n",
        "c_f(data1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDPttwM2aOFh",
        "colab_type": "code",
        "outputId": "bda692cf-8c73-47d4-bd20-8af17edb4b01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "data.dtypes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0                                     int64\n",
              "LoyalCH / WeekofPurchase / WeekofPurchase    float64\n",
              "LoyalCH / WeekofPurchase + PctDiscCH^2       float64\n",
              "LoyalCH / WeekofPurchase * STORE_4           float64\n",
              "WeekofPurchase                                 int64\n",
              "StoreID_1                                      int64\n",
              "STORE_2                                        int64\n",
              "Purchase                                       int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FA1DdUCWbcTp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}